{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b284cff8",
   "metadata": {},
   "source": [
    "# AirRaid-PPO implementation\n",
    "\n",
    "PPO test in the AirRaid environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d37ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.wrappers import AtariPreprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "basic_env = gym.make(\"GravitarNoFrameskip-v4\", obs_type = \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04544b5e",
   "metadata": {},
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5dca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_env = AtariPreprocessing(basic_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c963de",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "Class used to memorize the trajectory and calculate the advntage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b7a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    \n",
    "    STATE = 0\n",
    "    ACTION = 1\n",
    "    ACTION_PROB = 2\n",
    "    REWARD = 3\n",
    "    DONE = 4\n",
    "    \n",
    "    def __init__(self, n_trajectories, gamma = 0.4):\n",
    "        self.trajectories = np.empty(n_trajectories, dtype=object)\n",
    "        self.gamma = gamma\n",
    "              \n",
    "    def collect(self, state, action, action_prob, reward, done, i_episode):\n",
    "        if (self.trajectories[i_episode] == None):\n",
    "            self.trajectories[i_episode] = deque(maxlen=N_STEPS)\n",
    "        self.trajectories[i_episode].append((state, action, action_prob, reward, done))\n",
    "        \n",
    "    def calculate_advantages(self):\n",
    "        self.advantages = []\n",
    "        self.TDerrors = [] #list of all the delta, used to uopdate the critic\n",
    "        \n",
    "        for trajectory in self.trajectories:\n",
    "            \n",
    "            advantage_trajectory = [] #list of advantages for each element in a single trajectory\n",
    "            delta = []\n",
    "            \n",
    "            #print(trajectory[-1])\n",
    "            \n",
    "            old_advantage = trajectory[-1][self.REWARD]\n",
    "            delta.append(old_advantage)\n",
    "            advantage_trajectory.append(old_advantage)\n",
    "\n",
    "            for i in range(len(trajectory)-2,-1,-1):\n",
    "                delta.append(trajectory[i][self.REWARD] + self.gamma*ppo.return_v_values(trajectory[i+1][self.STATE]) - ppo.return_v_values(trajectory[i][self.STATE]))\n",
    "                new_advantage = delta[-1] + self.gamma*old_advantage\n",
    "                \n",
    "                advantage_trajectory.append(new_advantage[0])   \n",
    "                \n",
    "                old_advantage = new_advantage\n",
    "               \n",
    "            #reverse the list (at pos 0 there is the last advantage/delta)\n",
    "            advantage_trajectory = list(reversed(advantage_trajectory))\n",
    "            delta = list(reversed(delta))\n",
    "            \n",
    "            self.advantages.append(advantage_trajectory)\n",
    "            self.TDerrors.append(delta)\n",
    "            \n",
    "        #flat all trajectories in a single deque adding the advantages (easier to sample random batches)\n",
    "        self.flat_trajectories(self.trajectories, self.advantages, self.TDerrors)\n",
    "    \n",
    "    def flat_trajectories(self, trajectories, advantages, TDerrors):\n",
    "        \n",
    "        size = 0\n",
    "        for trajectory in trajectories:\n",
    "            size = size + len(trajectory)\n",
    "        \n",
    "        self.flatten_trajectories = deque(maxlen=size)\n",
    "        \n",
    "        for trajectory, advantage, delta in zip(trajectories, advantages, TDerrors):\n",
    "            for i in range(len(trajectory)):\n",
    "                self.flatten_trajectories.append((trajectory[i][self.STATE], trajectory[i][self.ACTION], trajectory[i][self.ACTION_PROB], trajectory[i][self.REWARD], advantage[i], delta[i], trajectory[i][self.DONE]))\n",
    "        \n",
    "        \n",
    "    #pick a random batch example from the flatten list of trajectories\n",
    "    def sample_experiences(self, batch_size):\n",
    "        if (len(self.flatten_trajectories) >= batch_size):\n",
    "            indices = np.random.permutation(len(self.flatten_trajectories))[:batch_size]\n",
    "        else:\n",
    "            indices = np.random.permutation(len(self.flatten_trajectories))\n",
    "        batch = [self.flatten_trajectories[index] for index in indices]\n",
    "        #delete form the memory the used obervations\n",
    "        for index in sorted(indices, reverse=True):\n",
    "            del self.flatten_trajectories[index]\n",
    "        states, actions, actions_prob, rewards, advantages, TDerrors, dones = [np.array([experience[field_index] for experience in batch]) for field_index in range(7)]\n",
    "        return states, actions, actions_prob, rewards, advantages, TDerrors, dones\n",
    "        \n",
    "    def reset(self):\n",
    "        for trajectory in self.trajectories:\n",
    "            trajectory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875cd80",
   "metadata": {},
   "source": [
    "# PPO class\n",
    "\n",
    "$ s_{t+1} $ is the observed state after the current action $ a_t $ \n",
    "\n",
    "Actor update formula:\n",
    "$ \\theta_{t+1} = \\theta_t + \\alpha\\nabla min(r_t(\\theta)\\hat{A}_t, clip(r_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A}_t)$\n",
    "\n",
    "Critic update formula:\n",
    "$ w_{t+1} = w_t + \\alpha\\delta_t\\nabla\\hat{v}(s_t,w)$\n",
    "\n",
    "Probability ratio $ r_t(\\theta) \\doteq $\n",
    "$ \\pi_\\theta(a_t | s_t) \\over \\pi_{\\theta_old}(a_t | s_t) $\n",
    "\n",
    "Advantage:\n",
    "$ \\hat{A}_t \\doteq \\delta_t + (\\gamma\\lambda)\\delta_{t+1} + (\\gamma\\lambda)^2\\delta_{t+2} + ... + (\\gamma\\lambda)^{T-t+1}\\delta_{T-1} = \\delta_t + (\\gamma\\lambda)\\hat{A}_{t+1}$\n",
    "\n",
    "TDerror:\n",
    "$ \\quad \\delta_t  \\doteq $\n",
    "$ r_t + \\gamma\\hat{v}(s_{t+1},w) - \\hat{v}(s_t,w) $ $ \\qquad $ (if $ s_{t+1} $ is terminal then $ \\hat{v}(s_{t+1},w) = 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b137fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(object):\n",
    "    \n",
    "    input_shape = [84,84,4] \n",
    "    n_outputs = wrapped_env.action_space.n\n",
    "    \n",
    "    def __init__(self, n_episodes = 1, train_steps = 100, epsilon = 0.2, alpha = 0.95):\n",
    "        self.actor = self.create_actor()\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "        self.critic = self.create_critic()\n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.train_steps = train_steps\n",
    "        \n",
    "        self.memory = Memory(n_episodes)\n",
    "        \n",
    "    #create the NN of the actor\n",
    "    # Given the state returns the probability of each action\n",
    "    def create_actor(self):    \n",
    "        actor = keras.Sequential([\n",
    "            keras.layers.Conv2D(filters=32, kernel_size = (8,8), strides=4, activation=\"relu\", input_shape = self.input_shape),\n",
    "            keras.layers.Conv2D(filters=64, kernel_size = (4,4), strides=2, activation=\"relu\"),\n",
    "            keras.layers.Conv2D(filters=64, kernel_size = (3,3), strides=1, activation=\"relu\"),\n",
    "            keras.layers.Dense(512),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            keras.layers.Dense(self.n_outputs, activation = 'softmax') ])\n",
    "        return actor\n",
    "       \n",
    "    #create the NN of the critic\n",
    "    # Given the state returns the value function\n",
    "    def create_critic(self):\n",
    "        critic = keras.Sequential([\n",
    "            keras.layers.Conv2D(filters=32, kernel_size = (8,8), strides=4, activation=\"relu\", input_shape = self.input_shape),\n",
    "            keras.layers.Conv2D(filters=64, kernel_size = (4,4), strides=2, activation=\"relu\"),\n",
    "            keras.layers.Conv2D(filters=64, kernel_size = (3,3), strides=1, activation=\"relu\"),\n",
    "            keras.layers.Dense(512),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            keras.layers.Dense(1) ])\n",
    "        \n",
    "        self.critic_loss_fn = tf.keras.losses.mean_squared_error\n",
    "        \n",
    "        return critic\n",
    "      \n",
    "    def play_one_step(self, env, observation):\n",
    "        action, action_prob = self.select_action(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        #put in wrapper\n",
    "        reward = float(reward)/100.\n",
    "        \n",
    "        obs1, r, d, i = env.step(0)\n",
    "        obs2, r, d, i = env.step(0)\n",
    "        obs3, r, d, i = env.step(0)\n",
    "\n",
    "        observation = tf.transpose(tf.squeeze(tf.stack([observation, obs1, obs2, obs3], axis = 0)), [1,2,0])\n",
    "        \n",
    "        self.memory.collect(observation, action, action_prob, reward, done, i_episode)\n",
    "        return observation, action, reward, done, info\n",
    "        \n",
    "    #select the action (returned as a number)\n",
    "    def select_action(self, observation):\n",
    "        \n",
    "        # explanation: tf.expand_dims(observation['pov'], axis=0)\n",
    "        # since we pass another input of shape (1,) -> we need to tell keras that is one image (it assumes the first dimension to be the batch)\n",
    "        action_probabilities = self.actor.predict(tf.expand_dims(observation, axis=0))[0]\n",
    "        \n",
    "        #choosing an action usign randomly using a \"roulette wheel\" approach\n",
    "        r = random.random()\n",
    "        \n",
    "        sum_probabilities = 0\n",
    "        for i in range(len(action_probabilities)):\n",
    "            sum_probabilities = sum_probabilities + action_probabilities[i]\n",
    "            \n",
    "            if (r <= sum_probabilities):\n",
    "                action = i\n",
    "                break\n",
    "        \n",
    "        return action, action_probabilities[action]\n",
    "    \n",
    "    def train(self, batch_size):\n",
    "        self.memory.calculate_advantages()\n",
    "        \n",
    "        for i_step in range(self.train_steps):\n",
    "            done = self.training_step(batch_size)\n",
    "            if (done):\n",
    "                break\n",
    "        \n",
    "        self.memory.reset()\n",
    "        \n",
    "    #training done on the memory (the advantages must be calculated before hand)\n",
    "    def training_step(self, batch_size):\n",
    "        #get experiences (parts of a trajectory) from the memory\n",
    "        experiences = self.memory.sample_experiences(batch_size)\n",
    "        states, actions, actions_prob, rewards, advantages, TDerrors, dones = experiences\n",
    "        \n",
    "        done = False\n",
    "        if (len(states) != batch_size):\n",
    "            done = True\n",
    "        \n",
    "        #compute the values for the update of the actor\n",
    "        \n",
    "        mask = tf.one_hot(actions, self.n_outputs)\n",
    "\n",
    "        states = states/255\n",
    "\n",
    "        #array of shape (64,) into array of shape (64,1)\n",
    "        #states =  np.array(np.array_split(states, len(states)))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            current_actions_prob = self.actor(states)\n",
    "            \n",
    "            current_action_prob = tf.reduce_sum(current_actions_prob*mask, axis=1, keepdims=True)\n",
    "            old_actions_prob = tf.reshape(tf.convert_to_tensor(actions_prob), [len(states), 1])\n",
    "            probability_ratio = tf.divide(current_action_prob, old_actions_prob)\n",
    "        \n",
    "            surrogate_arg_1 = tf.convert_to_tensor([probability_ratio[index]*advantages[index] for index in range(len(advantages))])\n",
    "            surrogate_arg_2 = tf.convert_to_tensor(np.array([tf.keras.backend.clip(probability_ratio,1-self.epsilon,1+self.epsilon)[index]*advantages[index] for index in range(len(advantages))]).flatten())\n",
    "            \n",
    "            L = 0 - tf.minimum( surrogate_arg_1 , surrogate_arg_2 ) \n",
    "            loss = tf.reduce_mean(L)\n",
    "\n",
    "        actor_weights = self.actor.trainable_variables\n",
    "        grads = tape.gradient(loss, actor_weights)\n",
    "        self.actor_optimizer.apply_gradients(zip(grads, actor_weights))\n",
    "        \n",
    "        #update of the critic. We need the target is the TD error\n",
    "        target_v_values = tf.reshape(tf.convert_to_tensor(np.asarray(self.alpha*TDerrors).astype('float32')), (len(states), 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            all_v_values = self.critic(states)\n",
    "            v_values = tf.reduce_sum(all_v_values*mask, axis=1, keepdims=True)\n",
    "            loss = tf.reduce_mean(self.critic_loss_fn(target_v_values, v_values))\n",
    "        grads = tape.gradient(loss, self.critic.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(zip(grads, self.critic.trainable_variables))\n",
    "        \n",
    "        #since v changed we need to re-calculate the advantages\n",
    "        #self.memory.calculate_advantages()\n",
    "        \n",
    "        return done\n",
    "    \n",
    "    def return_v_values(self, observation):\n",
    "        v = self.critic.predict(tf.expand_dims(observation, axis=0))[0]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2869d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bea6744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Impossibile cambiare la modalitÃ  del thread dopo averla impostata\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Episode 0 terminated after 165 steps with total reward: 0.0\n",
      "Epoch 0 Episode 1 terminated after 118 steps with total reward: 0.0\n",
      "(<tf.Tensor: shape=(84, 84, 4), dtype=int32, numpy=\n",
      "array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]])>, 9, 0.04947686, 0.0, True)\n",
      "(<tf.Tensor: shape=(84, 84, 4), dtype=int32, numpy=\n",
      "array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]])>, 15, 0.15197225, 0.0, True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paci3\\AppData\\Local\\Temp\\ipykernel_24376\\2025616523.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  states, actions, actions_prob, rewards, advantages, TDerrors, dones = [np.array([experience[field_index] for experience in batch]) for field_index in range(7)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3962\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3962\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3963\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Const'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m episode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_STEPS):   \n\u001b[1;32m---> 31\u001b[0m     observation, action, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     wrapped_env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     34\u001b[0m     episode_reward \u001b[38;5;241m=\u001b[39m episode_reward \u001b[38;5;241m+\u001b[39m reward\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mPPO.play_one_step\u001b[1;34m(self, env, observation)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_one_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, env, observation):\n\u001b[1;32m---> 48\u001b[0m     action, action_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m#put in wrapper\u001b[39;00m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mPPO.select_action\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[0;32m     65\u001b[0m     \n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# explanation: tf.expand_dims(observation['pov'], axis=0)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# since we pass another input of shape (1,) -> we need to tell keras that is one image (it assumes the first dimension to be the batch)\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     action_probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m#choosing an action usign randomly using a \"roulette wheel\" approach\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     r \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom()\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\keras\\engine\\training.py:1720\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1716\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1717\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1718\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1720\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py:1383\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py:1138\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1137\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py:320\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    318\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 320\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1903\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func):\n\u001b[0;32m   1871\u001b[0m   \u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \n\u001b[0;32m   1873\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1901\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1902\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1903\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5062\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   5060\u001b[0m \u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m-> 5062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5065\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5066\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`map_func` must return a `Dataset` object. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   5067\u001b[0m           \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)))\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4218\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4211\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   4212\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4213\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4214\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4215\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4216\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m-> 4218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4219\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3150\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3142\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m \n\u001b[0;32m   3144\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3148\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3150\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   3151\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3152\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3116\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3114\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3116\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3117\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   3118\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3119\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4195\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4189\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m   4190\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m   4191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m   4192\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   4193\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m   4194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m-> 4195\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4196\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m   4197\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4125\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m   4124\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m-> 4125\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m   4127\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:382\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    460\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py:305\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03mThis step can be accomplished in several ways. The most natural is to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m  A Dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    304\u001b[0m num_in_full_batch \u001b[38;5;241m=\u001b[39m num_full_batches \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m--> 305\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_in_full_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    307\u001b[0m     first_k_indices, [num_full_batches, batch_size])\n\u001b[0;32m    309\u001b[0m flat_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(first_k_indices)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1108\u001b[0m, in \u001b[0;36mslice\u001b[1;34m(input_, begin, size, name)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice\u001b[39m(input_, begin, size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1059\u001b[0m   \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m   \u001b[38;5;124;03m\"\"\"Extracts a slice from a tensor.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \n\u001b[0;32m   1062\u001b[0m \u001b[38;5;124;03m  See also `tf.strided_slice`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    A `Tensor` the same type as `input_`.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:9415\u001b[0m, in \u001b[0;36m_slice\u001b[1;34m(input, begin, size, name)\u001b[0m\n\u001b[0;32m   9413\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   9414\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 9415\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9416\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   9417\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   9418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:517\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    511\u001b[0m       values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    512\u001b[0m           values,\n\u001b[0;32m    513\u001b[0m           name\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    514\u001b[0m           as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref,\n\u001b[0;32m    515\u001b[0m           preferred_dtype\u001b[38;5;241m=\u001b[39mdefault_dtype)\n\u001b[0;32m    516\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 517\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    345\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 346\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:293\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    291\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    292\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 293\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    298\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    598\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3558\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3559\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3561\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3569\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3570\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2040\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2039\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_op_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m _create_c_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph, node_def, inputs,\n\u001b[0;32m   2042\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2043\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3966\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3963\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3964\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:\n\u001b[0;32m   3965\u001b[0m     \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 3966\u001b[0m     \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphGetOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   3969\u001b[0m     data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "N_EPISODES = 2 # number of trajectories collected in one epoch\n",
    "N_STEPS = 900 # max number of step for each episode\n",
    "\n",
    "TRAIN_STEPS = 30 # number of max steps done during training. if the number of samples is less than TRAIN_STEPS*BATCH_SIZE will stop early after completing the training on all the samples\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ppo = PPO(n_episodes = N_EPISODES, train_steps = TRAIN_STEPS)\n",
    "\n",
    "rewards = []\n",
    "\n",
    "\n",
    "for i_epoch in range(N_EPOCHS):\n",
    "    \n",
    "    epoch_reward = 0.0\n",
    "    \n",
    "    for i_episode in range(N_EPISODES):\n",
    "        \n",
    "        observation = wrapped_env.reset()\n",
    "        \n",
    "        obs1, reward, done, info = wrapped_env.step(0)\n",
    "        obs2, reward, done, info = wrapped_env.step(0)\n",
    "        obs3, reward, done, info = wrapped_env.step(0)\n",
    "\n",
    "        observation = tf.transpose(tf.squeeze(tf.stack([observation, obs1, obs2, obs3], axis = 0)), [1,2,0])\n",
    "        \n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        for i_step in range(N_STEPS):   \n",
    "            \n",
    "            observation, action, reward, done, info = ppo.play_one_step(wrapped_env, observation)\n",
    "\n",
    "            #wrapped_env.render()\n",
    "            episode_reward = episode_reward + reward\n",
    "\n",
    "            if(done or i_step == N_STEPS-1):\n",
    "                print(\"Epoch {} Episode {} terminated after {} steps with total reward: {}\".format(i_epoch, i_episode, i_step, episode_reward*100))\n",
    "                epoch_reward = epoch_reward + episode_reward\n",
    "                break\n",
    "                \n",
    "    rewards.append(epoch_reward/N_EPISODES)\n",
    "    \n",
    "    ppo.train(batch_size = 64)\n",
    "    \n",
    "wrapped_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5b122",
   "metadata": {},
   "source": [
    "## Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(N_EPOCHS)\n",
    "\n",
    "plt.plot(epochs, rewards)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d710415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
